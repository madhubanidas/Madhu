{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyPkHt/eocAbEXggr/R5ttDE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhubanidas/Madhu/blob/main/PYSPARK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niMOhOh2eVue",
        "outputId": "8c6b208b-3785-4b51-bcac-043a73231f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Starting spark Session**"
      ],
      "metadata": {
        "id": "4GtzGdSqnAqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "EGAXjMoOjPwm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "fxssdUBejTSt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = (SparkSession.builder\n",
        "  .appName(\"Practice\")\n",
        "  .getOrCreate())"
      ],
      "metadata": {
        "id": "iyZSrlRZjXMe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "pM9tinfDjxRQ",
        "outputId": "60682eea-a023-42e1-8277-ed35bc4036a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e31d693df10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b703a489fa62:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas"
      ],
      "metadata": {
        "id": "A1uv5ufYnP4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('test1.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "al66XTg6lEde",
        "outputId": "0bf5c7d4-9159-418e-9093-8c0b6517b766"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Name  Age  Experience\n",
              "0  Krish   31           7\n",
              "1  Madhu   23           2\n",
              "2  Jyoti   27           5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2687b93b-ea5a-461b-8534-d2d5db177d03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Krish</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Madhu</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jyoti</td>\n",
              "      <td>27</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2687b93b-ea5a-461b-8534-d2d5db177d03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2687b93b-ea5a-461b-8534-d2d5db177d03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2687b93b-ea5a-461b-8534-d2d5db177d03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-948f610f-6bc1-44bf-9650-a9d94ebd0c9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-948f610f-6bc1-44bf-9650-a9d94ebd0c9e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-948f610f-6bc1-44bf-9650-a9d94ebd0c9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Krish\",\n          \"Madhu\",\n          \"Jyoti\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 23,\n        \"max\": 31,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          31,\n          23,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pd.read_csv('test1.csv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Fw6jzx6jlY34",
        "outputId": "4a636b9d-6e4c-4297-d3f7-c0ee2ccf3bef"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading the Dataset**"
      ],
      "metadata": {
        "id": "64v6osbFmelM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('test1.csv')"
      ],
      "metadata": {
        "id": "XAOkn2m7j11c"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu1sgf_mkZtj",
        "outputId": "404e6f22-e500-4938-faa2-cabe413a5b71"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOeiEljRkitQ",
        "outputId": "c41721db-519b-4306-8be1-81723cf345cb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+\n",
            "|  _c0|_c1|       _c2|\n",
            "+-----+---+----------+\n",
            "| Name|Age|Experience|\n",
            "|Krish| 31|         7|\n",
            "|Madhu| 23|         2|\n",
            "|Jyoti| 27|         5|\n",
            "+-----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWRVT941PTXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.option('header','true').csv('test1.csv',inferSchema=True)\n",
        "##inferSchema=true will shows numbers as integers(or other datatypes) or everything will be considered as strings"
      ],
      "metadata": {
        "id": "7OKLsgY9kvuC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyGcvNljnvwU",
        "outputId": "0608d7eb-e840-46dc-949d-d88f49cd7240"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+\n",
            "| Name|Age|Experience|\n",
            "+-----+---+----------+\n",
            "|Krish| 31|         7|\n",
            "|Madhu| 23|         2|\n",
            "|Jyoti| 27|         5|\n",
            "+-----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##alternative easier method\n",
        "spark.read.csv('test1.csv',header=True,inferSchema=True).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59xlJmYPrYWu",
        "outputId": "7a313810-6d65-4f5c-927c-c855e0ccfbb0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+\n",
            "| Name|Age|Experience|\n",
            "+-----+---+----------+\n",
            "|Krish| 31|         7|\n",
            "|Madhu| 23|         2|\n",
            "|Jyoti| 27|         5|\n",
            "+-----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark **Dataframe**"
      ],
      "metadata": {
        "id": "ONMh_aTombki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "bCmFHGFzlhK6",
        "outputId": "b91eb85c-650c-4f6b-85d6-b0ac484ef0ec"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checking the Datatypes of the Column(Schema)**"
      ],
      "metadata": {
        "id": "8-3T_k-tmi2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55H7DILimJyq",
        "outputId": "defeece1-2d66-4c24-fd56-8da73261be5f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Selecting Columns and Indexing**"
      ],
      "metadata": {
        "id": "cyU67qKGmy2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlKResPkm_zm",
        "outputId": "80824a21-8715-42b0-ef46-30dbeaf39c2f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age', 'Experience']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBRyE-8Qlprq",
        "outputId": "1cb8c4e5-8078-4de8-ab88-84b0ee83ff11"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Krish', Age='31', Experience='7'),\n",
              " Row(Name='Madhu', Age='23', Experience='2')]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.tail(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS_SMhUQqR-1",
        "outputId": "9e36f36a-ea4d-4a09-9f29-2a5d3e2a85b7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Madhu', Age='23', Experience='2'),\n",
              " Row(Name='Jyoti', Age='27', Experience='5')]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select('Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CQIxnr5sW3W",
        "outputId": "c10edfe1-b0f1-4d63-d095-3169a7bc4f24"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7F7pVNfsizl",
        "outputId": "697a95e7-4ae4-43d9-f021-cde97ce78157"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| Name|\n",
            "+-----+\n",
            "|Krish|\n",
            "|Madhu|\n",
            "|Jyoti|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark.select('Name'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "3ssxiIRVsnSE",
        "outputId": "cf461f38-14c8-4806-893e-4016fc1755eb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(['Name','Experience'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jFd3-BGswGr",
        "outputId": "88c5eab0-6241-4d1a-df10-fd24a056e196"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Experience: int]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(['Name','Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqQRlIMys-A8",
        "outputId": "475df959-0104-4faf-e97f-7a713e12c83e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+\n",
            "| Name|Experience|\n",
            "+-----+----------+\n",
            "|Krish|         7|\n",
            "|Madhu|         2|\n",
            "|Jyoti|         5|\n",
            "+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw0CkfM_tOGS",
        "outputId": "d5b69d4d-eeae-474a-9f2f-6c674794a4d8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check Describe Option similar to Pandas**"
      ],
      "metadata": {
        "id": "Umz-_hqhmw2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35TEE65-tYA7",
        "outputId": "0eeafa71-88f7-4786-aed2-e7f5b0ecb803"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, Name: string, Age: string, Experience: string]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqy90NE8ttHt",
        "outputId": "ef3bb7cf-4d1b-4ada-a78a-a644e49ec0c6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+-----------------+\n",
            "|summary| Name| Age|       Experience|\n",
            "+-------+-----+----+-----------------+\n",
            "|  count|    3|   3|                3|\n",
            "|   mean| NULL|27.0|4.666666666666667|\n",
            "| stddev| NULL| 4.0|2.516611478423583|\n",
            "|    min|Jyoti|  23|                2|\n",
            "|    max|Madhu|  31|                7|\n",
            "+-------+-----+----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adding Columns**"
      ],
      "metadata": {
        "id": "ymciN3Gom5e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=df_pyspark.withColumn('Experience after 2 year',df_pyspark['Experience']+2)"
      ],
      "metadata": {
        "id": "67Fv6Gg_t_ge"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxSEcnnAvN8G",
        "outputId": "6d47350e-8b01-4e8b-cdc7-a6a2dd57ebb5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-----------------------+\n",
            "| Name|Age|Experience|Experience after 2 year|\n",
            "+-----+---+----------+-----------------------+\n",
            "|Krish| 31|         7|                      9|\n",
            "|Madhu| 23|         2|                      4|\n",
            "|Jyoti| 27|         5|                      7|\n",
            "+-----+---+----------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dropping Columns**"
      ],
      "metadata": {
        "id": "AyvI0c1Fm9Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=df_pyspark.drop('Experience after 2 year')"
      ],
      "metadata": {
        "id": "UQP3AMAtvsA4"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EZrTQasv6Zq",
        "outputId": "0c5384be-53e8-478f-8ada-f92ca91fc2f8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+\n",
            "| Name|Age|Experience|\n",
            "+-----+---+----------+\n",
            "|Krish| 31|         7|\n",
            "|Madhu| 23|         2|\n",
            "|Jyoti| 27|         5|\n",
            "+-----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rename Columns**"
      ],
      "metadata": {
        "id": "bhtLoQ74wDMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.withColumnRenamed('Name','New Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwqDjb4BwH25",
        "outputId": "50a56d36-ad94-41d5-ed97-c1cec8b3ed6b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+\n",
            "|New Name|Age|Experience|\n",
            "+--------+---+----------+\n",
            "|   Krish| 31|         7|\n",
            "|   Madhu| 23|         2|\n",
            "|   Jyoti| 27|         5|\n",
            "+--------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dropping Rows**"
      ],
      "metadata": {
        "id": "JVMyvZyKwhX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2=spark.read.csv('test2.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "BIJXleeYwoCF"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd8cNtulyydT",
        "outputId": "20f1cbee-7c74-4caa-b60f-463b224e1e10"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+-------+\n",
            "| Name| Age|Experience| Salary|\n",
            "+-----+----+----------+-------+\n",
            "|Krish|  31|         7|2000000|\n",
            "|Madhu|  23|         2| 900000|\n",
            "|Jyoti|  27|         5|1500000|\n",
            "|Harsh|  26|         4| 900000|\n",
            "|Rathi|  33|         9|2100000|\n",
            "| Mala|NULL|      NULL|5000000|\n",
            "| NULL|  34|        10|2500000|\n",
            "| NULL|  36|      NULL|   NULL|\n",
            "+-----+----+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.drop().show() #all colums with null value dropped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA-nYj3szB8e",
        "outputId": "f214aa64-c599-4b91-9d4f-88f835104087"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Various Parameter In Dropping Functionalities**"
      ],
      "metadata": {
        "id": "tQkPmMU5woeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##any=how\n",
        "df_pyspark2.na.drop(how='all').show() #all-will drop only those columns where all values in a row are null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_17RIiwzjVM",
        "outputId": "2d061566-e0e4-4828-c213-8100d774163d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+-------+\n",
            "| Name| Age|Experience| Salary|\n",
            "+-----+----+----------+-------+\n",
            "|Krish|  31|         7|2000000|\n",
            "|Madhu|  23|         2| 900000|\n",
            "|Jyoti|  27|         5|1500000|\n",
            "|Harsh|  26|         4| 900000|\n",
            "|Rathi|  33|         9|2100000|\n",
            "| Mala|NULL|      NULL|5000000|\n",
            "| NULL|  34|        10|2500000|\n",
            "| NULL|  36|      NULL|   NULL|\n",
            "+-----+----+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.drop(how='any').show() #all colums with null value dropped same as original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEC9-Js30uO0",
        "outputId": "41a32b89-5863-4328-ceaf-3c566b54783f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##threshold\n",
        "df_pyspark2.na.drop(how='any',thresh=2).show()\n",
        "##atleast 2 non null values should be present"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_rOnzlN0CFE",
        "outputId": "ac77551f-a85d-48e8-d560-7267eeed4186"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+-------+\n",
            "| Name| Age|Experience| Salary|\n",
            "+-----+----+----------+-------+\n",
            "|Krish|  31|         7|2000000|\n",
            "|Madhu|  23|         2| 900000|\n",
            "|Jyoti|  27|         5|1500000|\n",
            "|Harsh|  26|         4| 900000|\n",
            "|Rathi|  33|         9|2100000|\n",
            "| Mala|NULL|      NULL|5000000|\n",
            "| NULL|  34|        10|2500000|\n",
            "+-----+----+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.drop(thresh=3).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqEz_AUg0ePE",
        "outputId": "dce26d8c-521a-4c4c-f5a7-e28d27f5c9bd"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "| NULL| 34|        10|2500000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Subset\n",
        "df_pyspark2.na.drop(subset=['Experience']).show()\n",
        "##only columns with null values in experience dropped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPRzF7Z709gI",
        "outputId": "376abc4f-9e3f-4af8-8a87-8d3ea37f3863"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "| NULL| 34|        10|2500000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filling the Missing value**"
      ],
      "metadata": {
        "id": "25e0U3x61lgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.fill('Missing Values').show() #string can fill in string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW_m-m7T1pXO",
        "outputId": "ae451a94-0a22-42e6-84f0-2d856e6a594a"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+----------+-------+\n",
            "|          Name| Age|Experience| Salary|\n",
            "+--------------+----+----------+-------+\n",
            "|         Krish|  31|         7|2000000|\n",
            "|         Madhu|  23|         2| 900000|\n",
            "|         Jyoti|  27|         5|1500000|\n",
            "|         Harsh|  26|         4| 900000|\n",
            "|         Rathi|  33|         9|2100000|\n",
            "|          Mala|NULL|      NULL|5000000|\n",
            "|Missing Values|  34|        10|2500000|\n",
            "|Missing Values|  36|      NULL|   NULL|\n",
            "+--------------+----+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.fill(1,'Experience').show() #only integers can fill in integer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E95N3wrQ2H3d",
        "outputId": "0d5e4f80-7bd5-4acd-c143-7ed49046d7b8"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+-------+\n",
            "| Name| Age|Experience| Salary|\n",
            "+-----+----+----------+-------+\n",
            "|Krish|  31|         7|2000000|\n",
            "|Madhu|  23|         2| 900000|\n",
            "|Jyoti|  27|         5|1500000|\n",
            "|Harsh|  26|         4| 900000|\n",
            "|Rathi|  33|         9|2100000|\n",
            "| Mala|NULL|         1|5000000|\n",
            "| NULL|  34|        10|2500000|\n",
            "| NULL|  36|         1|   NULL|\n",
            "+-----+----+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.fill(30,['Experience','age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o90pkB2_2vqm",
        "outputId": "9e1abb6f-50e4-420c-f9a6-fc049d8cab89"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "| Mala| 30|        30|5000000|\n",
            "| NULL| 34|        10|2500000|\n",
            "| NULL| 36|        30|   NULL|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling Missing values by Mean,Median and Mode**"
      ],
      "metadata": {
        "id": "xQZP2wx_wxv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['Age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "yxd3MUphxAix"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Add imputation cols to df\n",
        "imputer.fit(df_pyspark2).transform(df_pyspark2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmXSLhwx3VQv",
        "outputId": "370c44ff-ef63-4cb0-ab54-d1746054805b"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+-------+-----------+------------------+--------------+\n",
            "| Name| Age|Experience| Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+-----+----+----------+-------+-----------+------------------+--------------+\n",
            "|Krish|  31|         7|2000000|         31|                 7|       2000000|\n",
            "|Madhu|  23|         2| 900000|         23|                 2|        900000|\n",
            "|Jyoti|  27|         5|1500000|         27|                 5|       1500000|\n",
            "|Harsh|  26|         4| 900000|         26|                 4|        900000|\n",
            "|Rathi|  33|         9|2100000|         33|                 9|       2100000|\n",
            "| Mala|NULL|      NULL|5000000|         30|                 6|       5000000|\n",
            "| NULL|  34|        10|2500000|         34|                10|       2500000|\n",
            "| NULL|  36|      NULL|   NULL|         36|                 6|       2128571|\n",
            "+-----+----+----------+-------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['Age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"median\")"
      ],
      "metadata": {
        "id": "c6B4aZ_g4eTE"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Add imputation cols to df\n",
        "imputer.fit(df_pyspark2).transform(df_pyspark2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98Di9Ba94lab",
        "outputId": "6daea567-800c-428e-abff-5bf5393fa2ec"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+-------+-----------+------------------+--------------+\n",
            "| Name| Age|Experience| Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+-----+----+----------+-------+-----------+------------------+--------------+\n",
            "|Krish|  31|         7|2000000|         31|                 7|       2000000|\n",
            "|Madhu|  23|         2| 900000|         23|                 2|        900000|\n",
            "|Jyoti|  27|         5|1500000|         27|                 5|       1500000|\n",
            "|Harsh|  26|         4| 900000|         26|                 4|        900000|\n",
            "|Rathi|  33|         9|2100000|         33|                 9|       2100000|\n",
            "| Mala|NULL|      NULL|5000000|         31|                 5|       5000000|\n",
            "| NULL|  34|        10|2500000|         34|                10|       2500000|\n",
            "| NULL|  36|      NULL|   NULL|         36|                 5|       2000000|\n",
            "+-----+----+----------+-------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filter Operation**"
      ],
      "metadata": {
        "id": "lK6w-AQw461g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3=spark.read.csv('test3.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "vOVbVo365P8V"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNI9zKgW6EIm",
        "outputId": "d434136e-4877-48a7-bab3-1f2e986307a6"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Salary of people less than or equal to 1500000\n",
        "df_pyspark3.filter('Salary<=1500000').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UBWWmh86JyD",
        "outputId": "638c0fa1-06c3-4e64-cbdb-ef28add2f619"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.filter('Salary<=1500000').select(['Name','Age']).show()##only shows name and age who fit the criteria"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrrwvwtS64kr",
        "outputId": "ba3dd62f-6800-4e1c-ad69-97c88c47c1ec"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Madhu| 23|\n",
            "|Jyoti| 27|\n",
            "|Harsh| 26|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.filter(df_pyspark3['Salary']>1400000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWESJzNN7LSj",
        "outputId": "da309606-0a56-408f-c10f-d37900e000db"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **& | ==**"
      ],
      "metadata": {
        "id": "SElWfMN45DUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.filter((df_pyspark3['Salary']>1400000)& (df_pyspark3['Salary']<2000000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDEWwGp25IX6",
        "outputId": "95dde591-8030-49d8-f96b-ac5c926b43bf"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Jyoti| 27|         5|1500000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.filter((df_pyspark3['Salary']>=2100000) | (df_pyspark3['Salary']<1000000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSuicKhlOFSd",
        "outputId": "66a44bf1-6343-432b-ee45-e48d2a60b9f5"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.filter((df_pyspark3['Salary']==1500000) | (df_pyspark3['Salary']<1000000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpWc4F_6O-lM",
        "outputId": "50365b4c-d325-4e71-90b4-2e7266825cc9"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **~**"
      ],
      "metadata": {
        "id": "I2WV9f4x5MPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.filter(~((df_pyspark3['Salary']>=2100000) | (df_pyspark3['Salary']<1000000))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTO0--EmOjKL",
        "outputId": "4fa90d13-57fa-45e7-b4f9-cae72c79aeab"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark3.filter(~(df_pyspark3['Salary']<=1500000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F48MpZJw5Q0z",
        "outputId": "b38ad217-de04-47f6-f583-6fc981b1275c"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PySpark GROUP BY and Aggregate Function**"
      ],
      "metadata": {
        "id": "BD3dM5M7PUea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4= spark.read.csv('test4.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "_fDUEAkYPgEk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpnmstJvKYnR",
        "outputId": "c8d09523-911a-4ba2-8f77-d9d98b74569f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------+-------+\n",
            "| Name|    Department| Salary|\n",
            "+-----+--------------+-------+\n",
            "|Krish|  Data Analyst|2000000|\n",
            "|Madhu|  Data Analyst|1200000|\n",
            "|Madhu|           SQL| 900000|\n",
            "|Jyoti|Cyber Security|1500000|\n",
            "|Jyoti|    Data Entry| 700000|\n",
            "|Jyoti|Senior Analyst|1700000|\n",
            "|Krish|Cyber Security|2300000|\n",
            "|Harsh|  Data Analyst| 900000|\n",
            "|Harsh|Senior Analyst|2100000|\n",
            "+-----+--------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz0yPZpJKef-",
        "outputId": "06ab207e-b484-4cd3-a501-7cc046a221c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GROUP BY"
      ],
      "metadata": {
        "id": "HooN1xR7K5DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.groupBy('Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV-m2e8xK3Kv",
        "outputId": "633647a1-e84b-4178-8f26-b9f3286ebd5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GroupedData[grouping expressions: [Name], value: [Name: string, Department: string ... 1 more field], type: GroupBy]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.groupBy('Name').sum().show() #Group to find maximum salary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwS4-z6iLTgj",
        "outputId": "f6e42ca6-b9c8-432f-af45-f49698376644"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+\n",
            "| Name|sum(Salary)|\n",
            "+-----+-----------+\n",
            "|Madhu|    2100000|\n",
            "|Jyoti|    3900000|\n",
            "|Krish|    4300000|\n",
            "|Harsh|    3000000|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.groupBy('Name').max().show() #max salary of each"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XxQhMxDNRRa",
        "outputId": "ef330e13-3695-422b-d179-92223fa3fc57"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+\n",
            "| Name|max(Salary)|\n",
            "+-----+-----------+\n",
            "|Madhu|    1200000|\n",
            "|Jyoti|    1700000|\n",
            "|Krish|    2300000|\n",
            "|Harsh|    2100000|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.groupBy('Name').min().show() #min salary of each"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqH0J791NlB0",
        "outputId": "994f4b0f-990d-4f82-a978-767ef1d5e92b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+\n",
            "| Name|min(Salary)|\n",
            "+-----+-----------+\n",
            "|Madhu|     900000|\n",
            "|Jyoti|     700000|\n",
            "|Krish|    2000000|\n",
            "|Harsh|     900000|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Groupby Department which gives most salary\n",
        "df_pyspark4.groupBy('Department').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3CWxRdoLl1e",
        "outputId": "c18f4faf-8722-4016-d9df-aee1992ca021"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+\n",
            "|    Department|sum(Salary)|\n",
            "+--------------+-----------+\n",
            "|Senior Analyst|    3800000|\n",
            "|    Data Entry|     700000|\n",
            "|  Data Analyst|    4100000|\n",
            "|           SQL|     900000|\n",
            "|Cyber Security|    3800000|\n",
            "+--------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mean salary of departments\n",
        "df_pyspark4.groupBy('Department').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM3OLaL_MBrG",
        "outputId": "dcd20f14-3a06-43d0-ce29-305554137129"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+\n",
            "|    Department|       avg(Salary)|\n",
            "+--------------+------------------+\n",
            "|Senior Analyst|         1900000.0|\n",
            "|    Data Entry|          700000.0|\n",
            "|  Data Analyst|1366666.6666666667|\n",
            "|           SQL|          900000.0|\n",
            "|Cyber Security|         1900000.0|\n",
            "+--------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many employees working in each department\n",
        "df_pyspark4.groupBy('Department').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H4KnbQ-MVtk",
        "outputId": "c5b721b0-2a26-47f4-b6cd-c4cfd8ea7b18"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|    Department|count|\n",
            "+--------------+-----+\n",
            "|Senior Analyst|    2|\n",
            "|    Data Entry|    1|\n",
            "|  Data Analyst|    3|\n",
            "|           SQL|    1|\n",
            "|Cyber Security|    2|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#avg salary of employees working in each department\n",
        "df_pyspark4.groupBy('Department').avg().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etAyHsYwN8wj",
        "outputId": "2c3dabda-56c3-436a-b1f7-fe1b14241af4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+\n",
            "|    Department|       avg(Salary)|\n",
            "+--------------+------------------+\n",
            "|Senior Analyst|         1900000.0|\n",
            "|    Data Entry|          700000.0|\n",
            "|  Data Analyst|1366666.6666666667|\n",
            "|           SQL|          900000.0|\n",
            "|Cyber Security|         1900000.0|\n",
            "+--------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate"
      ],
      "metadata": {
        "id": "jrkRHT9RMkye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#total sum of all salaries\n",
        "df_pyspark4.agg({'Salary':'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSgwHwl7MiJ1",
        "outputId": "83a65e5b-950f-411c-bc16-3bf22a51d3e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|   13300000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.agg({'Name':'sum'}).show() #sum/avg works but gives null for string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50tKlOx3NIjR",
        "outputId": "3fbb7e20-d4e2-4a16-cc5c-12e25e883825"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|sum(Name)|\n",
            "+---------+\n",
            "|     NULL|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark4.agg({'Salary':'avg'}).show() #sum works but gives null for string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxfPd24_OHJI",
        "outputId": "fe8406a1-8ec3-4a6d-9ceb-cb3980ea94ae"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|       avg(Salary)|\n",
            "+------------------+\n",
            "|1477777.7777777778|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PySpark ML**"
      ],
      "metadata": {
        "id": "kWYsYhGOPb1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training=spark.read.csv('test3.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "rz-2B55aPWQi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCVpw75YP1mR",
        "outputId": "6fc76003-8e3e-4d8b-e91e-e5bd62adbdfa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+\n",
            "| Name|Age|Experience| Salary|\n",
            "+-----+---+----------+-------+\n",
            "|Krish| 31|         7|2000000|\n",
            "|Madhu| 23|         2| 900000|\n",
            "|Jyoti| 27|         5|1500000|\n",
            "|Harsh| 26|         4| 900000|\n",
            "|Rathi| 33|         9|2100000|\n",
            "+-----+---+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vrAPMxTQE0K",
        "outputId": "fdfd60fb-3e41-4af1-ea49-56620c9b5344"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd9SkyRSP34m",
        "outputId": "658366ca-41c4-42a8-890f-26e867d44923"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salary Prediction"
      ],
      "metadata": {
        "id": "ycxBAYdeSRBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "#forming which is dependent(in the form of vector) and independent variable\n",
        "featureassembler=VectorAssembler(inputCols=['Age','Experience'],outputCol='Independent Features')"
      ],
      "metadata": {
        "id": "3e8PfYu7RWG5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shaping the data\n",
        "output=featureassembler.transform(training)"
      ],
      "metadata": {
        "id": "RoDjKzTXRteQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxJzxrugRzil",
        "outputId": "628bce40-b3c0-409e-b420-020cbf6b853e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+--------------------+\n",
            "| Name|Age|Experience| Salary|Independent Features|\n",
            "+-----+---+----------+-------+--------------------+\n",
            "|Krish| 31|         7|2000000|          [31.0,7.0]|\n",
            "|Madhu| 23|         2| 900000|          [23.0,2.0]|\n",
            "|Jyoti| 27|         5|1500000|          [27.0,5.0]|\n",
            "|Harsh| 26|         4| 900000|          [26.0,4.0]|\n",
            "|Rathi| 33|         9|2100000|          [33.0,9.0]|\n",
            "+-----+---+----------+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZGUsjhSSYaZ",
        "outputId": "8523c92b-4c31-493e-cf2e-11cf8cbf97f2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age', 'Experience', 'Salary', 'Independent Features']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#which columns we are using in the final model\n",
        "finalized_data=output.select('Independent Features','Salary')"
      ],
      "metadata": {
        "id": "MagSOPxLSkFE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Linear Regression**"
      ],
      "metadata": {
        "id": "y93ZlqSvTMw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "#train test split\n",
        "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
        "regressor=LinearRegression(featuresCol='Independent Features',labelCol='Salary')\n",
        "regressor=regressor.fit(train_data)"
      ],
      "metadata": {
        "id": "twV-r4LmTGlA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coefficients\n",
        "regressor.coefficients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOQJPq5HUo2X",
        "outputId": "54b21307-1684-4d45-9eeb-95b09b6104fd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([-2400000.0, 3600000.0])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##intercepts\n",
        "regressor.intercept"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q80xq_wkU6tY",
        "outputId": "7d7222cd-6d3b-44dd-bfb1-66b7ba0e1059"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48899999.99932456"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prediction**"
      ],
      "metadata": {
        "id": "x_2bzwcPXNq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results=regressor.evaluate(test_data)"
      ],
      "metadata": {
        "id": "1WHQsqRsVBWH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRwbORM_XyOA",
        "outputId": "336eeea2-6fd2-426f-e94e-2403c6266a8d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+------------------+\n",
            "|Independent Features| Salary|        prediction|\n",
            "+--------------------+-------+------------------+\n",
            "|          [27.0,5.0]|1500000|2099999.9999888614|\n",
            "|          [31.0,7.0]|2000000|-299999.9999725893|\n",
            "+--------------------+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La5Ei2dRX8aM",
        "outputId": "e3f40ab9-9704-4f5f-80c9-a82d8c8c8150"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1449999.9999807253, 2824999999930.272)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}